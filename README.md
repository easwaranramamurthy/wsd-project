# Word Sense Disambiguation Project for 10-701

##Sense2Vec Modifications

These are present in sense2vec_tests/sense2vec. Most of this code is forked from https://github.com/explosion/sense2vec with modifications included for parsing wikipedia dataset. Instructions for running the code are provided in the readme inside the folder.

A shortened version of the Wikipedia dataset is provided in datasets/wikipedia_sentences_tokenised_top_100000.txt. The MSH corpus containing ambiguous medical search terms is provided in datasets/MSHCorpus.zip


